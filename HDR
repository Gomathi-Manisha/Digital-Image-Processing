import os, glob, traceback
import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files


use_drive = False
drive_folder = "/content/drive/MyDrive/HDR_images"  # change if using drive

# -------------------------------------------------------------------------
# Helper: mount drive if requested
# -------------------------------------------------------------------------
if use_drive:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=False)
    # ensure the folder exists
    if not os.path.isdir(drive_folder):
        raise SystemExit(f"Drive folder not found: {drive_folder}\nCreate the folder in your Drive and put exposure images there.")
    work_dir = drive_folder
else:
    # use current working directory in Colab session
    work_dir = os.getcwd()

print("Working directory:", work_dir)
os.chdir(work_dir)

# -------------------------------------------------------------------------
# Helper: read EXIF exposure time
# -------------------------------------------------------------------------
from PIL import Image
from PIL.ExifTags import TAGS

def read_exif_exposure_time(path):
    try:
        im = Image.open(path)
        info = im._getexif()
        if not info:
            return None
        for tag, value in info.items():
            name = TAGS.get(tag, tag)
            if name == "ExposureTime":
                if isinstance(value, tuple) and len(value) == 2 and value[1] != 0:
                    return float(value[0]) / float(value[1])
                try:
                    return float(value)
                except:
                    return None
    except Exception:
        return None
    return None

# -------------------------------------------------------------------------
# Collect images: attempt to use files already present; otherwise prompt upload
# -------------------------------------------------------------------------
# Accept common extensions and ignore previously-saved step output files.
all_images = sorted(glob.glob(os.path.join(work_dir, "*.png")) + 
                    glob.glob(os.path.join(work_dir, "*.jpg")) + 
                    glob.glob(os.path.join(work_dir, "*.jpeg")))
# filter out step output files from previous runs
inputs = [os.path.basename(p) for p in all_images if not os.path.basename(p).lower().startswith("step") and "hdr" not in os.path.basename(p).lower() and "tonemapped" not in os.path.basename(p).lower()]

if len(inputs) == 0:
    # no images found -> prompt upload (only happens once if you want)
    print("No image files found in working dir. Please upload your exposure images (3+ recommended).")
    uploaded = files.upload()
    inputs = sorted([name for name in uploaded.keys()])
    print("Uploaded:", inputs)
else:
    print("Found image files in working dir (will use these):")
    print(inputs)

# You can override / reorder inputs here if needed:
# Example: inputs = ["img_dark.jpg","img_mid.jpg","img_bright.jpg"]
# Make sure inputs are ordered darkest -> brightest for best results.
# If your filenames don't reflect exposure order, set 'inputs' manually:
# inputs = ["32_1.png", "1_4.png", " ... "]

# Keep only first 6 exposures if many
inputs = inputs[:6]
n = len(inputs)
if n < 2:
    raise SystemExit("Need at least 2 input images. Upload 3 images for reliable HDR.")

print(f"Using {n} images (in order): {inputs}")

# -------------------------------------------------------------------------
# Exposure times: try EXIF; if not found for all, use assumed geometric series
# -------------------------------------------------------------------------
exif_times = [read_exif_exposure_time(os.path.join(work_dir, f)) for f in inputs]
if all(t is not None for t in exif_times):
    exposure_times = np.array(exif_times, dtype=np.float32)
    print("EXIF exposure times read for all files:", exposure_times.tolist())
else:
    # fallback: assume exposures are a geometric series (darkest -> brightest)
    exposure_times = np.array([1.0 / (2 ** (n - 1 - i)) for i in range(n)], dtype=np.float32)
    print("EXIF not found for every file. Using assumed exposure times (s):", exposure_times.tolist())
    print("If you know real shutter speeds, edit 'exposure_times' manually in the cell.")

# -------------------------------------------------------------------------
# Load images with OpenCV
# -------------------------------------------------------------------------
images = []
shapes = []
for f in inputs:
    p = os.path.join(work_dir, f)
    img = cv2.imread(p)
    if img is None:
        raise FileNotFoundError(f"Could not read {p}")
    images.append(img)
    shapes.append(img.shape[:2])
print("Loaded images. shapes (h,w):", shapes)

# -------------------------------------------------------------------------
# Ensure same size: choose smallest height & width
# -------------------------------------------------------------------------
heights = [s[0] for s in shapes]
widths  = [s[1] for s in shapes]
common_h = min(heights)
common_w = min(widths)
print(f"Resizing all images to common size (h,w) = ({common_h},{common_w})")
resized = []
for i, img in enumerate(images):
    if img.shape[0] != common_h or img.shape[1] != common_w:
        img_rs = cv2.resize(img, (common_w, common_h), interpolation=cv2.INTER_CUBIC)
        print(f"  Resized {inputs[i]} from {img.shape[:2]} to {img_rs.shape[:2]}")
    else:
        img_rs = img
        print(f"  Kept {inputs[i]} unchanged")
    resized.append(img_rs)
images = resized

# -------------------------------------------------------------------------
# Save input preview
# -------------------------------------------------------------------------
cols = 2
rows = (len(images) + cols - 1)//cols
plt.figure(figsize=(10, 5*rows))
for i, img in enumerate(images):
    ax = plt.subplot(rows, cols, i+1)
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax.set_title(f"Input {i+1}: {inputs[i]}")
    ax.axis("off")
plt.tight_layout()
plt.savefig("step0_inputs.png", dpi=150, bbox_inches='tight')
plt.show()
print("[SAVED] step0_inputs.png")

# -------------------------------------------------------------------------
# STEP 1: Estimate CRF
# -------------------------------------------------------------------------
print("\n[STEP 1] Estimating Camera Response Function (CRF) using Debevec...")
calibrate = cv2.createCalibrateDebevec()
response = calibrate.process(images, exposure_times)
print("[STEP 1] CRF computed. shape:", response.shape)

# Plot CRF
x = np.arange(256)
plt.figure(figsize=(8,4))
plt.plot(x, response[:,0,0], label='Blue')
plt.plot(x, response[:,0,1], label='Green')
plt.plot(x, response[:,0,2], label='Red')
plt.xlabel('Pixel value (0-255)')
plt.ylabel('Log exposure')
plt.title('Estimated Camera Response Function (CRF)')
plt.legend()
plt.grid(True)
plt.savefig("step1_crf_curve.png", dpi=150, bbox_inches='tight')
plt.show()
print("[SAVED] step1_crf_curve.png")

# -------------------------------------------------------------------------
# STEP 2: Merge exposures to HDR radiance map
# -------------------------------------------------------------------------
print("\n[STEP 2] Merging exposures to HDR radiance map...")
merge_debevec = cv2.createMergeDebevec()
hdr = merge_debevec.process(images, exposure_times, response)
print("[STEP 2] HDR created. dtype:", hdr.dtype, "min/max:", float(hdr.min()), float(hdr.max()))

# Save HDR .hdr
cv2.imwrite("step2_hdr_radiance.hdr", hdr)
print("[SAVED] step2_hdr_radiance.hdr")

# Log-scaled preview
hdr_vis = np.log(np.maximum(hdr[:,:,1], 1e-8))
hdr_vis = (hdr_vis - hdr_vis.min()) / (hdr_vis.max() - hdr_vis.min())
plt.figure(figsize=(6,8))
plt.imshow(hdr_vis, cmap='gray')
plt.title("HDR Radiance (log-scaled, G channel)")
plt.axis('off')
plt.savefig("step2_hdr_log_preview.png", dpi=150, bbox_inches='tight')
plt.show()
print("[SAVED] step2_hdr_log_preview.png")

# -------------------------------------------------------------------------
# STEP 3: Tone mapping (Drago)
# -------------------------------------------------------------------------
print("\n[STEP 3] Tone mapping (Drago)...")
gamma = 1.0; saturation = 1.0; bias = 0.85
tonemap = cv2.createTonemapDrago(gamma, saturation, bias)
ldr = tonemap.process(hdr.copy())
ldr_8bit = np.clip(ldr * 255, 0, 255).astype('uint8')
cv2.imwrite("step3_hdr_tonemapped.jpg", ldr_8bit)
print("[SAVED] step3_hdr_tonemapped.jpg")

plt.figure(figsize=(6,8))
plt.imshow(cv2.cvtColor(ldr_8bit, cv2.COLOR_BGR2RGB))
plt.title("Tone-mapped HDR (Drago)")
plt.axis('off')
plt.savefig("step3_hdr_tonemapped_preview.png", dpi=150, bbox_inches='tight')
plt.show()
print("[SAVED] step3_hdr_tonemapped_preview.png")

# -------------------------------------------------------------------------
# Offer downloads (Colab will prompt)
# -------------------------------------------------------------------------
to_download = ["step0_inputs.png", "step1_crf_curve.png", "step2_hdr_radiance.hdr",
               "step2_hdr_log_preview.png", "step3_hdr_tonemapped.jpg", "step3_hdr_tonemapped_preview.png"]

print("\nPreparing files for download:")
for fn in to_download:
    if os.path.exists(fn):
        print("  ", fn)
        files.download(fn)
    else:
        print("  (missing)", fn)

print("\n=== HDR pipeline finished ===")
